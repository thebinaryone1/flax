{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMNC51ldX-Nq"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/flax/blob/main/docs/notebooks/full_eval.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/google/flax/blob/main/docs/notebooks/full_eval.ipynb)\n",
    "\n",
    "This notebook only contains executable code cells for the examples mentioned in\n",
    "https://flax.readthedocs.io/en/latest/guides/full_eval.html\n",
    "\n",
    "Please refer to above link for a an explanation of the problem and the proposed solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um6ZK_o1W-Vu"
   },
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "62DTHYCYHWp1",
    "outputId": "b38d096f-58db-4d61-effa-eafa4c732826",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 72 kB 387 kB/s \n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 140 kB 4.5 MB/s \n",
      "\u001b[?25h  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q chex einops\n",
    "# tfds.split_for_jax_process() was added in 4.5.1\n",
    "!pip install -q tensorflow_datasets -U\n",
    "# flax.jax_utils.pad_shard_unpad() is only available at HEAD\n",
    "!pip install -q git+https://github.com/google/flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NdzAaRwVExA9"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import chex\n",
    "import einops\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import flax.jax_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "chex.set_n_cpu_devices(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E30SS9gCIvrV"
   },
   "outputs": [],
   "source": [
    "per_device_batch_size = 512\n",
    "dataset_name = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bZ-HWxKZHf6I",
    "outputId": "639262cb-b617-4561-c31f-60b33156a15f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "             [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FakeModel(nn.Module):\n",
    "  num_classes: int\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    return jax.nn.one_hot(jnp.zeros([len(x)], jnp.int32), self.num_classes)\n",
    "\n",
    "model = FakeModel(num_classes=10)\n",
    "variables = {}\n",
    "inputs = jnp.zeros([2, 28, 28, 1])\n",
    "model.apply(variables, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx65cZiiW_cq"
   },
   "source": [
    "### The problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yfGNjMBFWEUk",
    "outputId": "09f0c28b-d28e-4a7a-8afe-8797da44ad6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff2865d0c0240909b5123a16cab4847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({(272, 28, 28, 1): 1, (512, 28, 28, 1): 19})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last batch has different shape\n",
    "collections.Counter(\n",
    "    tuple(batch['image'].shape)\n",
    "    for batch in tfds.load('mnist', split='test').batch(per_device_batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eFPK-Oysl1YS",
    "outputId": "293bd0e4-011e-41b4-de48-a53b9cfd0958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to drop remainder when using multiple batch levels in a dataparallel\n",
    "# setup\n",
    "sum(\n",
    "    np.prod(batch['label'].shape)\n",
    "    for batch in tfds.load('mnist', split='test')\n",
    "        .batch(per_device_batch_size, drop_remainder=True)\n",
    "        .batch(jax.local_device_count())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DlAJwgYDmoxe",
    "outputId": "8bb353f3-98db-4645-e627-3c3683e36ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1667, 1667, 1667, 1667, 1666, 1666]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having different number of examples for different hosts will result in SPMD\n",
    "# violation when all examples are to be processed\n",
    "process_count = 6\n",
    "[\n",
    "    len(tfds.load(dataset_name, split=tfds.split_for_jax_process(\n",
    "        'test', process_index=process_index, process_count=process_count)))\n",
    "    for process_index in range(process_count)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oUb7QrR2Iwk9",
    "outputId": "19234b4a-9f9c-47c4-cbcc-5f7fb2573746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation (512, 28, 28, 1)\n",
      "retrigger compilation (272, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DeviceArray(980, dtype=int32), 10000, DeviceArray(0.098, dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline: simple batching, keep reminder\n",
    "# => leads to recompilation & only works on single device\n",
    "\n",
    "@jax.jit\n",
    "def get_preds(variables, inputs):\n",
    "  print('retrigger compilation', inputs.shape)\n",
    "  return model.apply(variables, inputs)\n",
    "\n",
    "ds = tfds.load(dataset_name, split='test')\n",
    "ds = ds.batch(per_device_batch_size, drop_remainder=False)\n",
    "\n",
    "correct = total = 0\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  preds = get_preds(variables, batch['image'])\n",
    "  total += len(batch['label'])\n",
    "  correct += (batch['label'] == preds.argmax(axis=1)).sum()\n",
    "\n",
    "correc = correct.item()\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dlJuEBcLKY94",
    "outputId": "e94cf79c-a033-4bc3-a086-75ecd8bd21f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation (512, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DeviceArray(814, dtype=int32), 8192, DeviceArray(0.09936523, dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when the remainder is dropped, we can use multiple devices and avoid\n",
    "# recompilations\n",
    "# => but results are incorrect\n",
    "\n",
    "@jax.pmap\n",
    "def get_preds(variables, inputs):\n",
    "  print('retrigger compilation', inputs.shape)\n",
    "  return model.apply(variables, inputs)\n",
    "\n",
    "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
    "# This `drop_remainder=True` is required so we can do a second batch level.\n",
    "ds = ds.batch(per_device_batch_size, drop_remainder=True)\n",
    "# This `drop_remainder=True` is required so we can avoid a recompilation.\n",
    "ds = ds.batch(jax.local_device_count(), drop_remainder=True)\n",
    "\n",
    "correct = total = 0\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  preds = get_preds(variables, batch['image'])\n",
    "  total += len(batch['label'].flatten())\n",
    "  correct += (batch['label'] == preds.argmax(axis=-1)).sum()\n",
    "\n",
    "correc = correct.item()\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfu54P0pJwEH"
   },
   "source": [
    "### The solution: padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIkNUHsfXKCp"
   },
   "source": [
    "#### Manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I1hg8paaasXj",
    "outputId": "2e6c611d-357e-4e51-99d8-47c24d785b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation (512, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(980, 10000, 0.098)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually padding\n",
    "# => precise & allows for data parallelism\n",
    "\n",
    "@jax.pmap\n",
    "def get_preds(variables, inputs):\n",
    "  print('retrigger compilation', inputs.shape)\n",
    "  return model.apply(variables, inputs)\n",
    "\n",
    "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
    "per_host_batch_size = per_device_batch_size * jax.local_device_count()\n",
    "ds = ds.batch(per_host_batch_size, drop_remainder=False)\n",
    "\n",
    "shard = lambda x: einops.rearrange(\n",
    "    x, '(d b) ... -> d b ...', d=jax.local_device_count())\n",
    "unshard = lambda x: einops.rearrange(x, 'd b ... -> (d b) ...')\n",
    "\n",
    "correct = total = 0\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  images = batch['image']\n",
    "  n = len(images)\n",
    "  padding = np.zeros([per_host_batch_size - n, *images.shape[1:]], images.dtype)\n",
    "  padded_images = np.concatenate([images, padding])\n",
    "  preds = unshard(get_preds(variables, shard(padded_images)))[:n]\n",
    "  total += n\n",
    "  correct += (batch['label'] == preds.argmax(axis=-1)).sum()\n",
    "\n",
    "correct = correct.item()\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wh6CymyjXQ-a"
   },
   "source": [
    "#### Using `pad_shard_unpad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pQX__5DfEX9g",
    "outputId": "71017214-c4ce-4da0-8db5-9300dba79c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation (512, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(980, 10000, 0.098)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as before, but using @pad_shard_unshard decorator\n",
    "\n",
    "# manually padding\n",
    "# => precise & allows for data parallelism\n",
    "\n",
    "@jax.pmap\n",
    "def get_preds(variables, inputs):\n",
    "  print('retrigger compilation', inputs.shape)\n",
    "  return model.apply(variables, inputs)\n",
    "\n",
    "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
    "per_host_batch_size = per_device_batch_size * jax.local_device_count()\n",
    "ds = ds.batch(per_host_batch_size, drop_remainder=False)\n",
    "\n",
    "correct = total = 0\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  preds = flax.jax_utils.pad_shard_unpad(get_preds)(\n",
    "      variables, batch['image'], min_device_batch=per_device_batch_size)\n",
    "  total += len(batch['image'])\n",
    "  correct += (batch['label'] == preds.argmax(axis=-1)).sum()\n",
    "\n",
    "correct = correct.item()\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing metrics in `eval_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation {'image': (512, 28, 28, 1), 'label': (512,), 'mask': (512,)}\n",
      "(980, 10000, 0.098)\n"
     ]
    }
   ],
   "source": [
    "# moving the metrics computation into `eval_step()` and using `static_return`\n",
    "\n",
    "# this pattern is often used with more complicated `clu.metrics`\n",
    "\n",
    "def eval_step(metrics, variables, batch):\n",
    "  print('retrigger compilation', {k: v.shape for k, v in batch.items()})\n",
    "  preds = model.apply(variables, batch['image'])\n",
    "  correct = (batch['mask'] & (batch['label'] == preds.argmax(axis=-1))).sum()\n",
    "  total = batch['mask'].sum()\n",
    "  return dict(\n",
    "      correct=metrics['correct'] + jax.lax.psum(correct, axis_name='batch'),\n",
    "      total=metrics['total'] + jax.lax.psum(total, axis_name='batch'),\n",
    "  )\n",
    "\n",
    "eval_step = jax.pmap(eval_step, axis_name='batch')\n",
    "eval_step = flax.jax_utils.pad_shard_unpad(\n",
    "    eval_step, static_argnums=(0, 1), static_return=True)\n",
    "\n",
    "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
    "per_host_batch_size = per_device_batch_size * jax.local_device_count()\n",
    "ds = ds.batch(per_host_batch_size, drop_remainder=False)\n",
    "\n",
    "metrics = flax.jax_utils.replicate(dict(\n",
    "    correct=jnp.array(0, jnp.int32),\n",
    "    total=jnp.array(0, jnp.int32),)\n",
    ")\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  batch['mask'] = np.ones_like(batch['label'])\n",
    "  metrics = eval_step(\n",
    "      metrics, variables, batch,\n",
    "      min_device_batch=per_device_batch_size)\n",
    "\n",
    "correct, total = metrics['correct'][0].item(), metrics['total'][0].item()\n",
    "correct, total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptn8NQeAXbeL"
   },
   "source": [
    "#### Multi-host complications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MjtmUUjWPV1X",
    "outputId": "70ee173a-dcdf-4136-a3e0-6685c09f8198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrigger compilation (512, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(980, 10000, 0.098)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# infinite zero padding\n",
    "\n",
    "def with_infinite_padding(dataset):\n",
    "  \"\"\"Adds \"infinite padding\" to the dataset.\"\"\"\n",
    "  filler_element = tf.nest.map_structure(\n",
    "      lambda spec: tf.zeros(spec.shape, spec.dtype)[None], dataset.element_spec)\n",
    "  filler_element['mask'] = [False]\n",
    "  filler_dataset = tf.data.Dataset.from_tensor_slices(filler_element)\n",
    "  dataset = dataset.map(\n",
    "      lambda features: dict(mask=True, **features),\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset.concatenate(filler_dataset.repeat(None))\n",
    "\n",
    "@jax.pmap\n",
    "def get_preds(variables, inputs):\n",
    "  print('retrigger compilation', inputs.shape)\n",
    "  return model.apply(variables, inputs)\n",
    "\n",
    "count_p = jax.pmap(\n",
    "    lambda mask: jax.lax.psum(mask.sum(), axis_name='batch'),\n",
    "    axis_name='batch',\n",
    ")\n",
    "count_correct_p = jax.pmap(\n",
    "    lambda labels, preds, mask:\n",
    "        jax.lax.psum((mask & (labels == preds)).sum(), axis_name='batch'),\n",
    "    axis_name='batch',\n",
    ")\n",
    "\n",
    "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
    "ds = with_infinite_padding(ds).batch(per_device_batch_size).batch(jax.local_device_count())\n",
    "\n",
    "correct = total = 0\n",
    "for batch in ds.as_numpy_iterator():\n",
    "  n = count_p(batch['mask'])[0].item()  # adds sync barrier\n",
    "  if not n: break\n",
    "\n",
    "  preds = get_preds(variables, batch['image']).argmax(axis=-1)\n",
    "  total += n\n",
    "  correct += count_correct_p(batch['label'], preds, batch['mask'])[0]\n",
    "\n",
    "correct = correct.item()\n",
    "correct, total, correct / total"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
